{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOFire Reaction Optimization Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows the example set out in https://github.com/experimental-design/bofire/blob/main/tutorials/basic_examples/Reaction_Optimization_Example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports we'll need in this notebook\n",
    "from pprint import pprint as pp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the optimization problem as a Reaction Domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bofire.data_models.domain.api import Domain\n",
    "from bofire.data_models.domain.api import Inputs, Outputs\n",
    "from bofire.data_models.features.api import (\n",
    "    ContinuousInput,\n",
    "    ContinuousOutput,\n",
    "    CategoricalInput,\n",
    "    CategoricalDescriptorInput,\n",
    ")  # we won't need all of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wish the temperature of the reaction to be between 30 and 110 °C\n",
    "temperature_feature = ContinuousInput(\n",
    "    key=\"Temperature\", bounds=[30.0, 110.0], unit=\"°C\"\n",
    ")\n",
    "\n",
    "# Catalyst Loading\n",
    "catalyst_loading_feature = ContinuousInput(\n",
    "    key=\"Catalyst Loading\", bounds=[0.5, 2], unit=\"%\"\n",
    ")\n",
    "\n",
    "# Residence Time\n",
    "residence_time_feature = ContinuousInput(\n",
    "    key=\"Residence Time\", bounds=[1 * 60, 10 * 60], unit=\"minutes\"\n",
    ")\n",
    "\n",
    "# Catalyst choice\n",
    "catalyst_feature = CategoricalInput(\n",
    "    key=\"Catalyst\",\n",
    "    categories=[\n",
    "        \"P1-L1\",\n",
    "        \"P2-L1\",\n",
    "        \"P1-L2\",\n",
    "        \"P1-L3\",\n",
    "        \"P1-L4\",\n",
    "        \"P1-L5\",\n",
    "        \"P1-L6\",\n",
    "        \"P1-L7\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# gather all individual features\n",
    "input_features = Inputs(\n",
    "    features=[\n",
    "        temperature_feature,\n",
    "        catalyst_loading_feature,\n",
    "        residence_time_feature,\n",
    "        catalyst_feature,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs: we wish to maximize the Yield\n",
    "# import Maximize Objective to tell the optimizer you wish to optimize\n",
    "from bofire.data_models.objectives.api import MaximizeObjective\n",
    "\n",
    "objective = MaximizeObjective(\n",
    "    w=1.0,\n",
    ")\n",
    "yield_feature = ContinuousOutput(key=\"Yield\", objective=objective)\n",
    "# create an output feature\n",
    "output_features = Outputs(features=[yield_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have\n",
    "print(\"input_features:\", input_features)\n",
    "print(\"output_features:\", output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The domain is now the object that holds the entire optimization problem / problem definition.\n",
    "domain = Domain(\n",
    "    inputs=input_features,\n",
    "    outputs=output_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can now have a pretty printout of your domain via\n",
    "(domain.inputs + domain.outputs).get_reps_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and you can access your domain features via\n",
    "for feature_key in (\n",
    "    domain.inputs.get_keys()\n",
    "):  # this will get all the feature names and loop over them\n",
    "    input_feature = domain.inputs.get_by_key(\n",
    "        feature_key\n",
    "    )  # we can extract the individual feature object by asking for it by name\n",
    "    print(feature_key, \"|\", input_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as well as the output features as\n",
    "# and you can access your domain features via\n",
    "for feature_key in (\n",
    "    domain.outputs.get_keys()\n",
    "):  # this will get all the feature names and loop over them\n",
    "    output_feature = domain.outputs.get_by_key(\n",
    "        feature_key\n",
    "    )  # we can extract the individual feature object by asking for it by name\n",
    "    print(feature_key, \" | \", output_feature.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(domain.inputs + domain.outputs).get_reps_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a toy Reaction to play around with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import summit\n",
    "import numpy as np\n",
    "\n",
    "name_map = {\n",
    "    \"Catalyst Loading\": \"catalyst_loading\",\n",
    "    \"Residence Time\": \"t_res\",\n",
    "    \"Temperature\": \"temperature\",\n",
    "    \"Catalyst\": \"catalyst\",\n",
    "    \"Yield\": \"yld\",\n",
    "    \"TON\": \"ton\",\n",
    "}\n",
    "candidates = pd.DataFrame(\n",
    "    {\n",
    "        \"Catalyst Loading\": [0.498],\n",
    "        \"Residence Time\": [600],\n",
    "        \"Temperature\": [30],\n",
    "        \"Catalyst\": [\"P1-L3\"],\n",
    "    }\n",
    ").rename(columns=name_map)\n",
    "emulator = summit.get_pretrained_reizman_suzuki_emulator(case=1)\n",
    "conditions = summit.DataSet.from_df(candidates)\n",
    "results = emulator.run_experiments(conditions, rtn_std=True).rename(\n",
    "    columns=dict(zip(name_map.values(), name_map.keys())),\n",
    ")\n",
    "experiments = pd.DataFrame(\n",
    "    {\n",
    "        \"Catalyst Loading\": results[\"Catalyst Loading\"],\n",
    "        \"Residence Time\": results[\"Residence Time\"],\n",
    "        \"Temperature\": results[\"Temperature\"],\n",
    "        \"Catalyst\": results[\"Catalyst\"],\n",
    "        \"Yield\": results[\"Yield\"],\n",
    "        \"valid_Yield\": 1,\n",
    "        \"TON\": results[\"TON\"],\n",
    "        \"valid_TON\": 1,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bofire.data_models.strategies.api import SoboStrategy\n",
    "from bofire.data_models.acquisition_functions.api import qEI\n",
    "\n",
    "import bofire.strategies.api as strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single objective BO strategy\n",
    "\n",
    "qExpectedImprovement = qEI()\n",
    "sobo_strategy_data_model = SoboStrategy(\n",
    "    domain=domain,\n",
    "    acquisition_function=qExpectedImprovement,\n",
    ")\n",
    "\n",
    "# map the strategy data model to the actual strategy that has functionality\n",
    "sobo_strategy = strategies.map(sobo_strategy_data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobo_strategy.tell(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since a BO strategy requries an underlying regression model for predictions, it requires a certain amount of initial experiments for it to be able to build such a model.\n",
    "\n",
    "In order to obtain initial experiments, one way is to (pseudo)randomly sample candidate points in the reaction domain. This can e.g. be done by the RandomStrategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random strategy\n",
    "from bofire.data_models.strategies.api import (\n",
    "    RandomStrategy as RandomStrategyModel,\n",
    ")\n",
    "\n",
    "random_strategy_model = RandomStrategyModel(domain=domain)\n",
    "# we have to provide the strategy with our optimization problem so it knows where to sample from.\n",
    "random_strategy = strategies.map(random_strategy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's ask for five random sets of conditions\n",
    "candidates = random_strategy.ask(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "you can have a look at the candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = util.evaluate_candidates(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This info can now be given to the bo strategy so it can use it to fit the underlying regression model it utilizes via the strategy.tell() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "sobo_strategy.tell(experiments, replace=True, retrain=True)\n",
    "print(f\"fit took {(time.time()-t1):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Using this data we can now get a proposal for a next point to evaluate via the sobo_strategy.ask(1) method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "new_candidate = sobo_strategy.ask(1)\n",
    "print(f\"SOBO step took {(time.time()-t1):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ask call now takes way longer, since first a GP model is fitted to the data, and the acquisition function EI is optimized to obtain the new proposed candidiates. Note that the predictied yield and standard deviation, as well as desirability function value (the underlying value the optimizer sees) are provided in the new_candidate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this strategy.ask() and strategy.tell() we can now do our optimization loop, where after each new proposal, the conditions obtained from ask are evaluated and added to the known datapoints via tell. This requires to refit the underling model in each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_budget = 10\n",
    "i = 0\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    i += 1\n",
    "    t1 = time.time()\n",
    "    # ask for a new experiment\n",
    "    new_candidate = sobo_strategy.ask(1)\n",
    "    new_experiment = util.evaluate_candidates(new_candidate)\n",
    "    sobo_strategy.tell(new_experiment)\n",
    "    print(f\"Iteration took {(time.time()-t1):.2f} seconds\")\n",
    "    # inform the strategy about the new experiment\n",
    "    # experiments = pd.concat([experiments,new_experiment],ignore_index=True)\n",
    "    if i > experimental_budget:\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have access to the experiments here\n",
    "sobo_strategy.experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plot of yield vs. Iteration\n",
    "sobo_strategy.experiments[\"Yield\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Objective Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bofire.data_models.objectives.api import MinimizeObjective\n",
    "from bofire.data_models.strategies.api import MoboStrategy\n",
    "from bofire.data_models.acquisition_functions.api import qEHVI\n",
    "\n",
    "max_objective = MaximizeObjective(w=1.0)\n",
    "min_objective = MinimizeObjective(w=1.0, bounds=[0, 200])\n",
    "\n",
    "yield_feature = ContinuousOutput(key=\"Yield\", objective=max_objective)\n",
    "ton_feature = ContinuousOutput(key=\"TON\", objective=min_objective)\n",
    "# create an output feature\n",
    "output_features = Outputs(features=[yield_feature, ton_feature])\n",
    "domain = Domain(\n",
    "    inputs=input_features,\n",
    "    outputs=output_features,\n",
    ")\n",
    "# a multi objective BO strategy\n",
    "\n",
    "qExpectedImprovement = qEHVI()\n",
    "mobo_strategy_data_model = MoboStrategy(\n",
    "    domain=domain,\n",
    "    acquisition_function=qExpectedImprovement,\n",
    ")\n",
    "\n",
    "# map the strategy data model to the actual strategy that has functionality\n",
    "mobo_strategy = strategies.map(mobo_strategy_data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random strategy\n",
    "from bofire.data_models.strategies.api import (\n",
    "    RandomStrategy as RandomStrategyModel,\n",
    ")\n",
    "\n",
    "random_strategy_model = RandomStrategyModel(domain=domain)\n",
    "# we have to provide the strategy with our optimization problem so it knows where to sample from.\n",
    "random_strategy = strategies.map(random_strategy_model)\n",
    "candidates = random_strategy.ask(5)\n",
    "experiments = util.evaluate_candidates(candidates)\n",
    "mobo_strategy.tell(experiments, replace=True, retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_budget = 10\n",
    "i = 0\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    i += 1\n",
    "    t1 = time.time()\n",
    "    # ask for a new experiment\n",
    "    new_candidate = mobo_strategy.ask(1)\n",
    "    new_experiment = util.evaluate_candidates(new_candidate)\n",
    "    mobo_strategy.tell(new_experiment)\n",
    "    print(f\"Iteration took {(time.time()-t1):.2f} seconds\")\n",
    "    # inform the strategy about the new experiment\n",
    "    # experiments = pd.concat([experiments,new_experiment],ignore_index=True)\n",
    "    if i > experimental_budget:\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobo_strategy.experiments[\"Yield\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobo_strategy.experiments[\"TON\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
